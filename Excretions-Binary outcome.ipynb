{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.core.display as di\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# This line will hide code by default when the notebook is exported as HTML\n",
    "# di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "# This line will add a button to toggle visibility of code blocks, for use with the HTML export version\n",
    "di.display_html('''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>''', raw=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This sub-project shows the effect of all parameters (Gender, Group P vs S, and Housing) combined on the 3 outcomes, Day1, Day2, and Day3. In other word, there is no dimentionality reduction.\n",
    "The results show the following:\n",
    "    1. The accuracies of all machine learning models were similar and consistence for Day1 and Day3.\n",
    "    2. Day2, which has the social factor involved, showed wide range of accuracies and inconsistency for all models.\n",
    "    3. The social factor might have great and fast impacts on behavior system? needs for more analyses to support this claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Group</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Day1</th>\n",
       "      <th>D1Category</th>\n",
       "      <th>Day2</th>\n",
       "      <th>D2Category</th>\n",
       "      <th>Day3</th>\n",
       "      <th>D3Category</th>\n",
       "      <th>Total</th>\n",
       "      <th>TotalCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10A1</td>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>10</td>\n",
       "      <td>med</td>\n",
       "      <td>6</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>low</td>\n",
       "      <td>18</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10B1</td>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>11</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>8</td>\n",
       "      <td>med</td>\n",
       "      <td>19</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6A1</td>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6B1</td>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>5</td>\n",
       "      <td>med</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "      <td>med</td>\n",
       "      <td>10</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49C1</td>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label   Sex Group        Housing  Day1 D1Category  Day2 D2Category  Day3  \\\n",
       "0  10A1  Male     P  (+Male+Cover)    10        med     6        med     2   \n",
       "1  10B1  Male     P  (+Male+Cover)    11       high     0        low     8   \n",
       "2   6A1  Male     P  (+Male+Cover)     0        low     0        low     0   \n",
       "3   6B1  Male     P  (+Male+Cover)     5        med     0        low     5   \n",
       "4  49C1  Male     P  (+Male+Cover)     0        low     0        low     0   \n",
       "\n",
       "  D3Category  Total TotalCategory  \n",
       "0        low     18          high  \n",
       "1        med     19          high  \n",
       "2        low      0           low  \n",
       "3        med     10           med  \n",
       "4        low      0           low  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv ('Analysis of Excretions.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Group</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Day1</th>\n",
       "      <th>Day2</th>\n",
       "      <th>Day3</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>P</td>\n",
       "      <td>(+Male+Cover)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sex Group        Housing  Day1  Day2  Day3  Total\n",
       "0  Male     P  (+Male+Cover)    10     6     2     18\n",
       "1  Male     P  (+Male+Cover)    11     0     8     19\n",
       "2  Male     P  (+Male+Cover)     0     0     0      0\n",
       "3  Male     P  (+Male+Cover)     5     0     5     10\n",
       "4  Male     P  (+Male+Cover)     0     0     0      0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['Sex', 'Group', 'Housing', 'Day1', 'Day2', 'Day3', 'Total']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_excretion (number):\n",
    "    if number == 0:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset ['Day1_binary'] = dataset['Day1'].apply(classify_excretion)\n",
    "dataset ['Day2_binary'] = dataset['Day2'].apply(classify_excretion)\n",
    "dataset ['Day3_binary'] = dataset['Day3'].apply(classify_excretion)\n",
    "dataset ['Total_binary'] = dataset['Total'].apply(classify_excretion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical variables\n",
    "dataset = pd.get_dummies(dataset, columns= [\"Sex\",\"Group\",\"Housing\"], prefix= [\"Sex\",\"Group\",\"Housing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day1</th>\n",
       "      <th>Day2</th>\n",
       "      <th>Day3</th>\n",
       "      <th>Total</th>\n",
       "      <th>Day1_binary</th>\n",
       "      <th>Day2_binary</th>\n",
       "      <th>Day3_binary</th>\n",
       "      <th>Total_binary</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Group_P</th>\n",
       "      <th>Group_S</th>\n",
       "      <th>Housing_(+Male+Cover)</th>\n",
       "      <th>Housing_(+Male-Cover)</th>\n",
       "      <th>Housing_(-Male+Cover)</th>\n",
       "      <th>Housing_(-Male-Cover)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day1  Day2  Day3  Total Day1_binary Day2_binary Day3_binary Total_binary  \\\n",
       "0    10     6     2     18           1           1           1            1   \n",
       "1    11     0     8     19           1           0           1            1   \n",
       "2     0     0     0      0           0           0           0            0   \n",
       "\n",
       "   Sex_Female  Sex_Male  Group_P  Group_S  Housing_(+Male+Cover)  \\\n",
       "0           0         1        1        0                      1   \n",
       "1           0         1        1        0                      1   \n",
       "2           0         1        1        0                      1   \n",
       "\n",
       "   Housing_(+Male-Cover)  Housing_(-Male+Cover)  Housing_(-Male-Cover)  \n",
       "0                      0                      0                      0  \n",
       "1                      0                      0                      0  \n",
       "2                      0                      0                      0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating matrix of features to identify the dependent factor vs independent factors (parameters)\n",
    "# Avoid the dummy variable trap is done by dropping 1 dummy variable from each category. Some libraries do it for you \n",
    "X = dataset.iloc[:, [8,10,12,13,14]].values  \n",
    "y = dataset.iloc[:, 7].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0) # you can ommit random_state. It \n",
    "# keeps the same random sample for all sampling trials OR you can choose different value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import StandardScaler\\nsc_X = StandardScaler()\\nX_train = sc_X.fit_transform(X_train) # X_train needs for fit and transform\\nX_test = sc_X.transform(X_test)       # X_test needs for only transform\\n\\n# sc_y = StandardScaler()\\n# y_train = sc_y.fit_transform(y_train)\\n# y_test = sc_y.transform(y_test)'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling. This for bringing large and small values of different parameters on the same scale.Not needed for this dataset\n",
    "# Here we will use Standardisation Scale.\n",
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) # X_train needs for fit and transform\n",
    "X_test = sc_X.transform(X_test)       # X_test needs for only transform\n",
    "\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)\n",
    "# y_test = sc_y.transform(y_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A) Fitting Logistic Regression to the Training set\n",
    "# Creating logestic regression class (classifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  0],\n",
       "       [31,  0]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
      "  0.66666667  0.66666667  0.66666667]\n",
      "0.69\n",
      "0.0152752523165\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation (evaluating the model performance)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print (accuracies)\n",
    "print (accuracies.mean ())\n",
    "print (accuracies.std ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B) Fitting KNN to the Training set\n",
    "# Creating KNN class (classifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57,  9],\n",
       "       [28,  3]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5         0.4         0.4         0.7         0.6         0.8         0.6\n",
      "  0.77777778  0.55555556  0.55555556]\n",
      "0.588888888889\n",
      "0.132030673578\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print (accuracies)\n",
    "print (accuracies.mean ())\n",
    "print (accuracies.std ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C) Fitting SVC to the Training set. The assumption is that the data is linearly separable.\n",
    "# Creating SVC class (classifier)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  0],\n",
       "       [31,  0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
      "  0.66666667  0.66666667  0.66666667]\n",
      "0.69\n",
      "0.0152752523165\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print (accuracies)\n",
    "print (accuracies.mean ())\n",
    "print (accuracies.std ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D) Fitting kernel SVC to the Training set. The assumption is that the data is NOT-linearly separable.\n",
    "# Creating kernel SVC class (classifier)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  0],\n",
       "       [31,  0]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
      "  0.66666667  0.66666667  0.66666667]\n",
      "0.69\n",
      "0.0152752523165\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print (accuracies)\n",
    "print (accuracies.mean ())\n",
    "print (accuracies.std ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E) Fitting Naive Bayes to the Training set. The assumption is that the parameters are independant.\n",
    "# Creating Naive Bayes class (classifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB() # naive bayes has no arguements\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 19],\n",
       "       [30, 24]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63636364  0.27272727  0.72727273  0.8         0.66666667  0.22222222\n",
      "  0.44444444  0.77777778  0.33333333  0.88888889]\n",
      "0.57696969697\n",
      "0.227344455572\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print (accuracies)\n",
    "print (accuracies.mean ())\n",
    "print (accuracies.std ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters. Here is just the code. Excuting the code on many\n",
    "# independent variables is time and computation comsuming. We will do it after dimentionality reduction.\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{\"C\": [1000, 1500, 2000, 3000], 'kernel': ['linear']},\n",
    "              {\"C\": [1000, 1500, 2000, 3000], 'kernel': ['rbf'], 'gamma': [0.05, 0.01, 0.02, 0.03, 0.04]}] #if you get 0.5 as the best\n",
    "                                                    # then exchange 0.001 and 0.0001 by 0.2, 0.3, 0.4, 0.5,0.6,0.7,0.8,and 0.9\n",
    "grid_search = GridSearchCV (estimator = classifier,\n",
    "                            param_grid = parameters,\n",
    "                            scoring = 'accuracy',\n",
    "                            cv = 10,\n",
    "                            n_jobs = -1)\n",
    "grid_search = grid_search.fit (X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_ \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659793814433\n",
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# print (best_accuracy)\n",
    "# print (best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the summaries of all models for Day1, Day2, and Day3\n",
    "Each summary starts with the name of the ML model then followed by the following:\n",
    "1. array. It is (2x2 table) showing true positive, true negative, false positive, and false negative.\n",
    "2. list of accuries for k-fold cross valisation. The list has 10 results.\n",
    "3. accuracies.mean. It represents the mean of the 10 accuracies of k-fold cross validation.\n",
    "4. accuracies.std. It represents the standard deviation of the 10 accuracies of k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Day1 Logestic Regression\n",
    "\n",
    "array\n",
    "([[66,  0],\n",
    "  [31,  0]])\n",
    "\n",
    "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7   0.66666667  0.66666667  0.66666667]\n",
    "\n",
    "accuracies.mean = 0.69\n",
    "\n",
    "accuracies.std = 0.0152752523165 \n",
    "\n",
    "Day1 KNN\n",
    "\n",
    "array([[50, 16],\n",
    "       [25,  6]])\n",
    "       \n",
    "[ 0.5         0.6         0.7         0.7         0.6         0.7         0.6\n",
    "  0.77777778  0.55555556  0.55555556]\n",
    "0.628888888889\n",
    "0.0819816299809  \n",
    "\n",
    "Day1 SVC\n",
    "\n",
    "array([[66,  0],\n",
    "       [31,  0]])\n",
    "       \n",
    "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
    "  0.66666667  0.66666667  0.66666667]\n",
    "0.69\n",
    "0.0152752523165 \n",
    "\n",
    "Day1 Kernel SVC\n",
    "\n",
    "array([[66,  0],\n",
    "       [31,  0]])\n",
    "       \n",
    "[ 0.7         0.5         0.7         0.7         0.7         0.7         0.6\n",
    "  0.66666667  0.66666667  0.55555556]\n",
    "0.648888888889\n",
    "0.0685295286449   \n",
    "\n",
    "Day1 Naive Bayes\n",
    "\n",
    "array([[66,  0],\n",
    "       [31,  0]])\n",
    "       \n",
    "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
    "  0.55555556  0.66666667  0.55555556]\n",
    "0.667777777778\n",
    "0.0569708610813 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Day2 Logestic Regression\n",
    "\n",
    "array([[41, 15],\n",
    "       [31, 10]])\n",
    "\n",
    "[ 0.63636364  0.36363636  0.4         0.6         0.6         0.11111111\n",
    "  0.55555556  0.44444444  0.33333333  0.66666667]\n",
    "0.471111111111\n",
    "0.164865814102 \n",
    "\n",
    "Day2 KNN\n",
    "\n",
    "array([[41, 15],\n",
    "       [28, 13]])\n",
    "       \n",
    "[ 0.36363636  0.54545455  0.9         0.8         0.6         0.11111111\n",
    "  0.66666667  0.55555556  0.44444444  0.55555556]\n",
    "0.554242424242\n",
    "0.209645022857\n",
    "\n",
    "Day2 SVC\n",
    "\n",
    "array([[46, 10],\n",
    "       [33,  8]])\n",
    "\n",
    "[ 0.54545455  0.36363636  0.4         0.7         0.4         0.22222222\n",
    "  0.55555556  0.33333333  0.44444444  0.55555556]\n",
    "0.45202020202\n",
    "0.13108702367 \n",
    "\n",
    "Day2 Kernel SVC\n",
    "\n",
    "array([[39, 17],\n",
    "       [28, 13]])\n",
    "       \n",
    "[ 0.63636364  0.45454545  0.8         0.8         0.4         0.11111111\n",
    "  0.66666667  0.44444444  0.22222222  0.66666667]\n",
    "0.520202020202\n",
    "0.222174926096\n",
    "\n",
    "Day2 Naive Bayes\n",
    "\n",
    "array([[36, 20],\n",
    "       [19, 22]])\n",
    "\n",
    "[ 0.63636364  0.45454545  0.6         0.7         0.6         0.11111111\n",
    "  0.55555556  0.55555556  0.22222222  0.88888889]\n",
    "0.532424242424\n",
    "0.213529930266 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Day3 Logestic Regression\n",
    "\n",
    "array([[66,  0],\n",
    "       [31,  0]])\n",
    "\n",
    "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
    "  0.7         0.77777778  0.75      ]\n",
    "0.712777777778\n",
    "0.0262995563968 \n",
    "\n",
    "Day3 KNN\n",
    "\n",
    "array([[45, 21],\n",
    "       [25,  6]])\n",
    "       \n",
    "[ 0.6         0.5         0.6         0.6         0.5         0.7         0.8\n",
    "  0.7         0.66666667  0.625     ]\n",
    "0.629166666667\n",
    "0.0875\n",
    "\n",
    "Day3 SVC\n",
    "\n",
    "array([[66,  0],\n",
    "       [31,  0]])\n",
    "       \n",
    "[ 0.7         0.7         0.7         0.7         0.7         0.7         0.7\n",
    "  0.7         0.77777778  0.75      ]\n",
    "0.712777777778\n",
    "0.0262995563968 \n",
    "\n",
    "Day3 Kernel SVC\n",
    "array([[57,  9],\n",
    "       [30,  1]])\n",
    "       \n",
    "[ 0.7         0.6         0.6         0.7         0.7         0.7         0.7\n",
    "  0.6         0.77777778  0.625     ]\n",
    "0.670277777778\n",
    "0.0573064374898 \n",
    "\n",
    "Day3 Naive Bayes\n",
    "\n",
    "array([[61,  5],\n",
    "       [31,  0]])\n",
    "       \n",
    "[ 0.7         0.7         0.6         0.7         0.7         0.7         0.7\n",
    "  0.6         0.66666667  0.875     ]\n",
    "0.694166666667\n",
    "0.07169088738  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Total Logestic Regression\n",
    "\n",
    "array([[30, 13],\n",
    "       [33, 21]])\n",
    "\n",
    "[ 0.45454545  0.36363636  0.54545455  0.7         0.66666667  0.22222222\n",
    "  0.33333333  0.55555556  0.22222222  0.77777778]\n",
    "0.484141414141\n",
    "0.187172589356 \n",
    "\n",
    "Total KNN\n",
    "\n",
    "array([[18, 25],\n",
    "       [15, 39]])\n",
    "       \n",
    "[ 0.63636364  0.63636364  0.72727273  0.8         0.66666667  0.22222222\n",
    "  0.66666667  0.55555556  0.66666667  0.66666667]\n",
    "0.624444444444\n",
    "0.146743586697\n",
    "\n",
    "Total SVC\n",
    "\n",
    "array([[37,  6],\n",
    "       [42, 12]])\n",
    "       \n",
    "[ 0.45454545  0.27272727  0.45454545  0.8         0.66666667  0.22222222\n",
    "  0.55555556  0.55555556  0.44444444  0.77777778]\n",
    "0.520404040404\n",
    "0.182477368463  \n",
    "\n",
    "Total Kernel SVC\n",
    "\n",
    "array([[28, 15],\n",
    "       [23, 31]])\n",
    "       \n",
    "[ 0.63636364  0.54545455  0.72727273  0.6         0.66666667  0.22222222\n",
    "  0.66666667  0.66666667  0.55555556  0.66666667]\n",
    "0.595353535354\n",
    "0.135184728144\n",
    "\n",
    "Total Naive Bayes\n",
    "\n",
    "array([[24, 19],\n",
    "       [30, 24]])\n",
    "\n",
    "[ 0.63636364  0.27272727  0.72727273  0.8         0.66666667  0.22222222\n",
    "  0.44444444  0.77777778  0.33333333  0.88888889]\n",
    "0.57696969697\n",
    "0.227344455572  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next step is repeating all above models after applying dimentionality reduction.\n",
    "1. The reduction will be statistics and experience based.\n",
    "2. The two parameters will be included in the dataset are Gender and Group (pair vs single)\n",
    "3. For dimentionality reducted sub-projects, please follow the links:\n",
    "4. for Day1 https://github.com/al-naimi/Voles/blob/master/Excretory-DR-BinaryOutcome.Day1.ipynb\n",
    "5. for Day2 https://github.com/al-naimi/Voles/blob/master/Excretory-DR-BinaryOutcome.Day2.ipynb\n",
    "6. for Day3 https://github.com/al-naimi/Voles/blob/master/Excretory-DR-BinaryOutcome.Day3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### End of the current sub-project. Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
